{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23d367c-c46f-4cc7-8877-7f1cb10c8810",
   "metadata": {},
   "source": [
    "# Model Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f08b7-73d6-4837-a145-6c43ea3a1686",
   "metadata": {},
   "source": [
    "## Part 1: Multinomial Naive Bayes Classifier on Mushroom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b34512-2036-41c4-9ceb-a54af3b01b0d",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "Multinomial Naive Bayes is a variation of the Naive Bayes classification algorithm that works with categorical features. It is traditionally used for text classification tasks such as spam filtering and sentiment analysis, but it can also be applied to datasets with categorical features, such as the Mushroom Dataset. It contains features that describe different mushroom species, classified as either edible or poisonous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d5605-a50a-4e1e-8702-fe82006d83a5",
   "metadata": {},
   "source": [
    "### 2. About the Mushroom Dataset\n",
    "The Mushroom dataset provides information about many mushroom species from the Agaricus and Lepiota families. These species are identified based on a range of characteristics, and the goal is to classify them as either edible (e) or poisonous (p).\n",
    "This dataset consists of more than 8000 samples. They include 23 species of gilled mushrooms, with attributes such as cap shape, cap surface, odor, gill attachment, stalk shape, and more.\n",
    "\n",
    "**Attribute Information:**\n",
    "cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "\n",
    "cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "\n",
    "cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "\n",
    "bruises: bruises=t,no=f\n",
    "\n",
    "odor: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
    "\n",
    "gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "\n",
    "gill-spacing: close=c,crowded=w,distant=d\n",
    "\n",
    "gill-size: broad=b,narrow=n\n",
    "\n",
    "gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "\n",
    "stalk-shape: enlarging=e,tapering=t\n",
    "\n",
    "stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,**missing=?**\n",
    "\n",
    "stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "\n",
    "stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "\n",
    "stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "\n",
    "stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "\n",
    "veil-type: partial=p,universal=u\n",
    "\n",
    "veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "\n",
    "ring-number: none=n,one=o,two=t\n",
    "\n",
    "ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "\n",
    "spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "\n",
    "population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "\n",
    "habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ceec9f-4701-4402-93ab-903c90ec07c7",
   "metadata": {},
   "source": [
    "### 3. Model Overview\n",
    "The Multinomial Naive Bayes algorithm is based on the assumption that the features are conditionally independent. This simplifies computations, but it may not always reflect real-world relationships, because some features in the Mushroom dataset in fact could be correlated. Despite this, the independence assumption often works well in practice, as it captures the overall structure of the data without requiring too much computations.\n",
    "\n",
    "The model also assumes that features are categorical. For datasets with continuous features, this approach would not be suitable, and a different variant, such as Gaussian Naive Bayes, would be necessary.\n",
    "\n",
    "The classifier is implemented using NumPy and collections.defaultdict for managing feature probabilities. train_test_split function from sklearn library was also used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48741b54-2346-47b5-af32-71fabd4d02e7",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation and Performance\n",
    "The performance of the model is evaluated based on the accuracy of its predictions. Accuracy is a proportion of correct predictions compared to its total number. The train-test split ensures that the model is evaluated on data that wasn't seen before.\n",
    "\n",
    "The average classifier's accuracy for 100 tests was 99.1%. This value shows the model's ability to classify mushrooms correctly by given features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb5223c-5ce3-4f3f-89bb-b4e7c20480a3",
   "metadata": {},
   "source": [
    "## Part 2: Gaussian Naive Bayes Classifier on Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee14fb-370e-4f5f-bf3e-cb5ccb20ff7f",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "Gaussian Naive Bayes Classificator is another version of the Naive Bayes algorithm that works with continuous data. The Gaussian version assumes that features follow a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945875a-d0ef-4cc4-a8da-2a485e36b4b0",
   "metadata": {},
   "source": [
    "### 2. About the Iris Dataset\n",
    "The Iris dataset contains measurements for three classes of iris flowers, each consisting of 50 samples. The goal is to classify flowers into species based on provided features.\n",
    "\n",
    "Features in the Dataset:\n",
    "- Sepal length (in cm)\n",
    "- Sepal width (in cm)\n",
    "- Petal length (in cm)\n",
    "- Petal width (in cm)\n",
    "\n",
    "Class Labels:\n",
    "- Setosa\n",
    "- Versicolor\n",
    "- Virginica\n",
    "\n",
    "This dataset is suitable for Gaussian Naive Bayes Classificator because all features are continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070b62f-bffa-4336-aee1-91e7454368aa",
   "metadata": {},
   "source": [
    "### 3. Model Overview\n",
    "The model calculates probabilities using the Gaussian probability density function for each feature. Main assumption is that features are normally distributed. This simplifies the probability calculations but main good classification ability for continuous data.\n",
    "\n",
    "The model is implemented using NumPy and collections.defaultdict. The train-test split is performed using the train_test_split function from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13be8e3-b5da-4863-9978-78c16bcb287d",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation and Performance\n",
    "The performance of the Gaussian Naive Bayes model is measured by its ability to classify flowers into species. The dataset is divided into training and testing sets to evaluate the model's generalization performance.\n",
    "\n",
    "The average classifier's accuracy for 100 tests was 95.3%.\n",
    "The combination of small dataset size, overlapping feature distributions between classes, and imperfect adherence to the Gaussian assumption explains why the accuracy is not as high as in the previous case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_kernel",
   "language": "python",
   "name": "my_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
